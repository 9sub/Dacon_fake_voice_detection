{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "361d73a1",
      "metadata": {
        "papermill": {
          "duration": 0.007011,
          "end_time": "2024-04-08T18:51:47.130888",
          "exception": false,
          "start_time": "2024-04-08T18:51:47.123877",
          "status": "completed"
        },
        "tags": [],
        "id": "361d73a1"
      },
      "source": [
        "# Drive mount & Unzip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmXtRnWN3bS0",
        "outputId": "3b7ff651-5249-405f-faa6-a3a84341ba11"
      },
      "id": "KmXtRnWN3bS0",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# 파일 경로 입력\n",
        "zip_file_name = '/content/drive/MyDrive/DACON/open.zip'\n",
        "\n",
        "# 압축 해제할 경로 입력\n",
        "extraction_dir = '/content/dataset'\n",
        "\n",
        "# 압축 해제\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extraction_dir)"
      ],
      "metadata": {
        "id": "q5qdeE9f3cML"
      },
      "id": "q5qdeE9f3cML",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sJHQhYn3gCb",
        "outputId": "ae06031e-8175-464f-acbf-102184560cfa"
      },
      "id": "_sJHQhYn3gCb",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "J6X_c5zd-SKH"
      },
      "id": "J6X_c5zd-SKH"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bbadbd56",
      "metadata": {
        "papermill": {
          "duration": 12.650384,
          "end_time": "2024-04-08T18:51:59.788340",
          "exception": false,
          "start_time": "2024-04-08T18:51:47.137956",
          "status": "completed"
        },
        "tags": [],
        "id": "bbadbd56"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "#import torchmetrics\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2d80cf24-13e8-480c-94eb-2982bb52510d",
      "metadata": {
        "id": "2d80cf24-13e8-480c-94eb-2982bb52510d"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f64eb379-e527-46c4-8b12-ead8db628070",
      "metadata": {
        "id": "f64eb379-e527-46c4-8b12-ead8db628070"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0d2de5d",
      "metadata": {
        "papermill": {
          "duration": 0.007241,
          "end_time": "2024-04-08T18:51:59.803571",
          "exception": false,
          "start_time": "2024-04-08T18:51:59.796330",
          "status": "completed"
        },
        "tags": [],
        "id": "a0d2de5d"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1a32fb60",
      "metadata": {
        "papermill": {
          "duration": 0.016983,
          "end_time": "2024-04-08T18:51:59.828208",
          "exception": false,
          "start_time": "2024-04-08T18:51:59.811225",
          "status": "completed"
        },
        "tags": [],
        "id": "1a32fb60"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    SR = 32000\n",
        "    N_MFCC = 128\n",
        "    # Dataset\n",
        "    ROOT_FOLDER = './'\n",
        "    # Training\n",
        "    N_CLASSES = 2\n",
        "    #BATCH_SIZE = 96\n",
        "    BATCH_SIZE = 48\n",
        "    N_EPOCHS = 10\n",
        "    LR = 3e-4\n",
        "\n",
        "    CLIP_VALUE = 1.0\n",
        "    # Others\n",
        "    SEED = 42\n",
        "\n",
        "CONFIG = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6700bf8e-7f43-4eac-9bea-25eb1d95fb12",
      "metadata": {
        "id": "6700bf8e-7f43-4eac-9bea-25eb1d95fb12"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(CONFIG.SEED) # Seed 고정"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터 2초 단위로 나누기"
      ],
      "metadata": {
        "id": "4nvB89Dz4R7I"
      },
      "id": "4nvB89Dz4R7I"
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "\n",
        "# CSV 파일 로드\n",
        "df_train = pd.read_csv('train.csv')\n",
        "\n",
        "# 데이터 저장을 위한 리스트 초기화\n",
        "mfcc_data = []\n",
        "mel_data = []\n",
        "label_data = []\n",
        "real_chunks = []\n",
        "fake_chunks = []\n",
        "\n",
        "# 라벨 카운트 초기화\n",
        "label_count = {'real': 0, 'fake': 0, 'combined': 0}\n",
        "\n",
        "def segment_audio(audio, sample_rate, segment_length=2):\n",
        "    segment_samples = segment_length * sample_rate\n",
        "    segments = []\n",
        "    for i in range(0, len(audio), segment_samples):\n",
        "        segment = audio[i:i+segment_samples]\n",
        "        segments.append(segment)\n",
        "    return segments\n",
        "\n",
        "def random_pad(mels, pad_size, mfcc=True):\n",
        "    pad_width = pad_size - mels.shape[1]\n",
        "    if pad_width <= 0:\n",
        "        return mels  # 패딩이 필요 없는 경우 원본 배열 반환\n",
        "    rand = np.random.rand()\n",
        "    left = int(pad_width * rand)\n",
        "    right = pad_width - left\n",
        "\n",
        "    if mfcc:\n",
        "        mels = np.pad(mels, pad_width=((0, 0), (left, right)), mode='constant')\n",
        "        local_max, local_min = mels.max(), mels.min()\n",
        "        mels = (mels - local_min) / (local_max - local_min)\n",
        "    else:\n",
        "        local_max, local_min = mels.max(), mels.min()\n",
        "        mels = (mels - local_min) / (local_max - local_min)\n",
        "        mels = np.pad(mels, pad_width=((0, 0), (left, right)), mode='constant')\n",
        "\n",
        "    return mels\n",
        "\n",
        "def add_noise(audio, noise_factor=0.05):\n",
        "    noise = np.random.randn(len(audio))\n",
        "    augmented_audio = audio + noise_factor * noise\n",
        "    augmented_audio = augmented_audio.astype(type(audio[0]))\n",
        "    return augmented_audio\n",
        "\n",
        "def overlay_audio(audio_2s, audio_1s, sr):\n",
        "    max_offset = len(audio_2s) - len(audio_1s)\n",
        "    start_position = random.randint(0, max_offset)\n",
        "    combined_audio = np.copy(audio_2s)\n",
        "    combined_audio[start_position:start_position+len(audio_1s)] += audio_1s\n",
        "    return combined_audio\n",
        "\n",
        "# 데이터셋에서 각 오디오 파일에 대해 처리\n",
        "for index, row in tqdm(df_train.iterrows()):\n",
        "    audio_path = row['path']\n",
        "    label = row['label']\n",
        "\n",
        "    # 오디오 파일 로드\n",
        "    y, sr = librosa.load(audio_path, sr=CONFIG.SR)\n",
        "\n",
        "    # 오디오 데이터 자르기\n",
        "    segments = segment_audio(y, sr, segment_length=2)\n",
        "\n",
        "    for chunk in segments:\n",
        "        # 노이즈 추가\n",
        "        if random.random() < 0.5:  # 일정 비율의 오디오에 노이즈 추가\n",
        "            chunk = add_noise(chunk)\n",
        "\n",
        "        if label == 'real':\n",
        "            if len(chunk) < int(1.5 * sr):\n",
        "                continue  # 1.5초보다 짧은 chunk는 무시\n",
        "            elif len(chunk) < int(2.0 * sr):\n",
        "                # 패딩하여 저장\n",
        "                chunk = np.pad(chunk, (0, int(2.0 * sr) - len(chunk)), mode='constant')\n",
        "                mfcc = librosa.feature.mfcc(y=chunk, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
        "                mels = librosa.feature.melspectrogram(y=chunk, sr=sr, n_mels=CONFIG.N_MFCC)\n",
        "                mels = librosa.power_to_db(mels, ref=np.max)\n",
        "                mfcc_data.append(random_pad(mfcc, pad_size=CONFIG.N_MFCC, mfcc=True))\n",
        "                mel_data.append(random_pad(mels, pad_size=CONFIG.N_MFCC, mfcc=False))\n",
        "                label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n",
        "                label_vector[1] = 1\n",
        "                label_data.append(label_vector)\n",
        "                label_count['real'] += 1\n",
        "            else:\n",
        "                real_chunks.append(chunk)\n",
        "        elif label == 'fake':\n",
        "            if len(chunk) < int(1.0 * sr):\n",
        "                continue  # 1초보다 짧은 chunk는 무시\n",
        "            elif len(chunk) < int(1.5 * sr):\n",
        "                fake_chunks.append(chunk)\n",
        "            else:\n",
        "                # 패딩하여 저장\n",
        "                chunk = np.pad(chunk, (0, int(2.0 * sr) - len(chunk)), mode='constant')\n",
        "                mfcc = librosa.feature.mfcc(y=chunk, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
        "                mels = librosa.feature.melspectrogram(y=chunk, sr=sr, n_mels=CONFIG.N_MFCC)\n",
        "                mels = librosa.power_to_db(mels, ref=np.max)\n",
        "                mfcc_data.append(random_pad(mfcc, pad_size=CONFIG.N_MFCC, mfcc=True))\n",
        "                mel_data.append(random_pad(mels, pad_size=CONFIG.N_MFCC, mfcc=False))\n",
        "                label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n",
        "                label_vector[0] = 1\n",
        "                label_data.append(label_vector)\n",
        "                label_count['fake'] += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nkc8q58u4GWN",
        "outputId": "6f8df137-e5b4-423f-977f-9eaae1a8ab13"
      },
      "id": "Nkc8q58u4GWN",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "55438it [16:34, 55.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fake 데이터와 Real 데이터를 합성하여 새로운 데이터 생성\n",
        "for fake_chunk in tqdm(fake_chunks):\n",
        "\n",
        "    real_chunk = real_chunks.pop(0)  # 순서대로 처리\n",
        "    combined_audio = overlay_audio(real_chunk, fake_chunk, sr)\n",
        "\n",
        "    # 노이즈 추가\n",
        "    if random.random() < 0.5:  # 일정 비율의 오디오에 노이즈 추가\n",
        "        combined_audio = add_noise(combined_audio)\n",
        "\n",
        "    # MFCC 추출\n",
        "    mfcc = librosa.feature.mfcc(y=combined_audio, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
        "\n",
        "    # Mel spectrogram 추출\n",
        "    mels = librosa.feature.melspectrogram(y=combined_audio, sr=sr, n_mels=CONFIG.N_MFCC)\n",
        "    mels = librosa.power_to_db(mels, ref=np.max)\n",
        "\n",
        "    # 랜덤 패딩\n",
        "    pad_size = 128\n",
        "\n",
        "    # 데이터 저장\n",
        "    mfcc_data.append(random_pad(mfcc, pad_size=pad_size, mfcc=True))\n",
        "    mel_data.append(random_pad(mels, pad_size=pad_size, mfcc=False))\n",
        "    label_vector = np.ones(CONFIG.N_CLASSES, dtype=float)  # [1,1] 레이블\n",
        "    label_data.append(label_vector)\n",
        "    label_count['combined'] += 1\n",
        "\n",
        "# Overlay remaining real data to create new combined data\n",
        "combined_real_chunks = real_chunks[:30228]\n",
        "for i in tqdm(range(0, len(combined_real_chunks), 2)):\n",
        "    if i + 1 >= len(combined_real_chunks):\n",
        "        break\n",
        "    real_chunk1 = combined_real_chunks[i]\n",
        "    real_chunk2 = combined_real_chunks[i + 1]\n",
        "    combined_audio = overlay_audio(real_chunk1, real_chunk2, sr)\n",
        "\n",
        "    # 노이즈 추가\n",
        "    if random.random() < 0.5:  # 일정 비율의 오디오에 노이즈 추가\n",
        "        combined_audio = add_noise(combined_audio)\n",
        "\n",
        "    # Extract MFCC features\n",
        "    mfcc = librosa.feature.mfcc(y=combined_audio, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
        "\n",
        "    # Extract Mel spectrogram features\n",
        "    mels = librosa.feature.melspectrogram(y=combined_audio, sr=sr, n_mels=CONFIG.N_MFCC)\n",
        "    mels = librosa.power_to_db(mels, ref=np.max)\n",
        "\n",
        "    # Random padding\n",
        "    pad_size = 128\n",
        "\n",
        "    # Save data\n",
        "    mfcc_data.append(random_pad(mfcc, pad_size=pad_size, mfcc=True))\n",
        "    mel_data.append(random_pad(mels, pad_size=pad_size, mfcc=False))\n",
        "    label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n",
        "    label_vector[1] = 1  # 'real' label\n",
        "    label_data.append(label_vector)\n",
        "    label_count['real'] += 1\n",
        "\n",
        "# Remove used real chunks from the original list\n",
        "real_chunks = real_chunks[30228:]\n",
        "\n",
        "# Remaining real chunks 처리하여 저장\n",
        "for real_chunk in tqdm(real_chunks):\n",
        "    mfcc = librosa.feature.mfcc(y=real_chunk, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
        "    mels = librosa.feature.melspectrogram(y=real_chunk, sr=sr, n_mels=CONFIG.N_MFCC)\n",
        "    mels = librosa.power_to_db(mels, ref=np.max)\n",
        "    mfcc_data.append(random_pad(mfcc, pad_size=CONFIG.N_MFCC, mfcc=True))\n",
        "    mel_data.append(random_pad(mels, pad_size=CONFIG.N_MFCC, mfcc=False))\n",
        "    label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n",
        "    label_vector[1] = 1\n",
        "    label_data.append(label_vector)\n",
        "    label_count['real'] += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmZpg3cv0IIs",
        "outputId": "b0353c97-aa52-4a16-c2d9-bca535005229"
      },
      "id": "EmZpg3cv0IIs",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10049/10049 [04:39<00:00, 36.02it/s]\n",
            "100%|██████████| 15114/15114 [14:14<00:00, 17.68it/s]\n",
            "100%|██████████| 8380/8380 [04:51<00:00, 28.71it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 리스트를 넘파이 배열로 변환\n",
        "mfcc_data = np.array(mfcc_data)\n",
        "mel_data = np.array(mel_data)\n",
        "label_data = np.array(label_data)\n",
        "\n",
        "print(\"MFCC 데이터 형태:\", mfcc_data.shape)\n",
        "print(\"Mel 스펙트로그램 데이터 형태:\", mel_data.shape)\n",
        "print(\"라벨 데이터 형태:\", label_data.shape)\n",
        "print(\"레이블 분포:\", label_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv3qyvma4ylN",
        "outputId": "4ebddc4f-d6bc-4851-fb87-ec05d46b236a"
      },
      "id": "cv3qyvma4ylN",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MFCC 데이터 형태: (55881, 128, 128)\n",
            "Mel 스펙트로그램 데이터 형태: (55881, 128, 128)\n",
            "라벨 데이터 형태: (55881, 2)\n",
            "레이블 분포: {'real': 30473, 'fake': 15359, 'combined': 10049}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.save('/content/drive/MyDrive/DACON/chunk/aug_mfcc_data.npy',mfcc_data)\n",
        "np.save('/content/drive/MyDrive/DACON/chunk/aug_mel_data.npy',mel_data)\n",
        "np.save('/content/drive/MyDrive/DACON/chunk/aug_label_data.npy',label_data)"
      ],
      "metadata": {
        "id": "-DNn_JwG_yrN"
      },
      "id": "-DNn_JwG_yrN",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mfcc_data.shape)\n",
        "print(mel_data.shape)\n",
        "print(label_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyF0Y484JKPL",
        "outputId": "d878fddb-96ed-4ec4-a121-207c9178ddb4"
      },
      "id": "UyF0Y484JKPL",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55881, 128, 128)\n",
            "(55881, 128, 128)\n",
            "(55881, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_mel_data=np.load('/content/drive/MyDrive/DACON/chunk/test_mel_data.npy')\n",
        "test_mfcc_data=np.load('/content/drive/MyDrive/DACON/chunk/test_mfcc_data.npy')\n",
        "\n",
        "print(test_mel_data.shape)\n",
        "print(test_mfcc_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcxnB5I348_s",
        "outputId": "1e6e7e5b-69ac-4abe-e952-0427b983b6d5"
      },
      "id": "QcxnB5I348_s",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 128, 128)\n",
            "(100000, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mfcc_data=np.load('/content/drive/MyDrive/DACON/chunk/aug_mfcc_data.npy')\n",
        "mel_data=np.load('/content/drive/MyDrive/DACON/chunk/aug_mel_data.npy')\n",
        "label_data=np.load('/content/drive/MyDrive/DACON/chunk/aug_label_data.npy')\n",
        "\n",
        "print(mfcc_data.shape)\n",
        "print(mel_data.shape)\n",
        "print(label_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xenkPunKmoQ",
        "outputId": "c6f7c737-e216-4e7a-bf28-1879a956204d"
      },
      "id": "5xenkPunKmoQ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(55881, 128, 128)\n",
            "(55881, 128, 128)\n",
            "(55881, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라벨 분포 확인"
      ],
      "metadata": {
        "id": "TDFFAnEB_EcB"
      },
      "id": "TDFFAnEB_EcB"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 라벨 분포 확인\n",
        "unique, counts = np.unique(label_data, axis=0, return_counts=True)\n",
        "label_counts = {str(label): count for label, count in zip(unique, counts)}\n",
        "\n",
        "# 출력\n",
        "print(\"Label distribution:\")\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "# 라벨 분포를 시각화\n",
        "labels = [str(label) for label in unique]\n",
        "counts = counts\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(labels, counts, color='skyblue')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Label Distribution')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "44a1wUer5Erw",
        "outputId": "1db51725-d732-43b7-ec7b-e0af67e5000a"
      },
      "id": "44a1wUer5Erw",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution:\n",
            "[0. 1.]: 30473\n",
            "[1. 0.]: 15359\n",
            "[1. 1.]: 10049\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# new label - label 균형\n",
        "'''\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# 라벨 분포 확인\n",
        "unique, counts = np.unique(label_data, axis=0, return_counts=True)\n",
        "label_counts = {str(label): count for label, count in zip(unique, counts)}\n",
        "\n",
        "# 출력\n",
        "print(\"Label distribution:\")\n",
        "for label, count in label_counts.items():\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "# 클래스별 데이터 인덱스 추출\n",
        "class_01_idx = np.where((label_data == [0, 1]).all(axis=1))[0]\n",
        "class_10_idx = np.where((label_data == [1, 0]).all(axis=1))[0]\n",
        "class_11_idx = np.where((label_data == [1, 1]).all(axis=1))[0]\n",
        "\n",
        "# 소수 클래스의 샘플 수 확인\n",
        "min_class_samples = len(class_10_idx)\n",
        "\n",
        "# 초반 10049개 제외\n",
        "class_01_idx_to_use = class_01_idx[10049:]\n",
        "\n",
        "# 다수 클래스에서 소수 클래스 샘플 수만큼 랜덤 샘플링\n",
        "class_01_sampled_idx = np.random.choice(class_01_idx_to_use, min_class_samples, replace=False)\n",
        "\n",
        "# 새로운 데이터셋 생성\n",
        "new_indices = np.concatenate([class_01_sampled_idx, class_10_idx, class_11_idx])\n",
        "np.random.shuffle(new_indices)  # 섞기\n",
        "\n",
        "# 데이터셋 추출\n",
        "new_mel_data = mel_data[new_indices]\n",
        "new_mfcc_data = mfcc_data[new_indices]\n",
        "new_label_data = label_data[new_indices]\n",
        "\n",
        "# 남은 [0, 1] 인덱스 추출\n",
        "remaining_class_01_idx = np.setdiff1d(class_01_idx, class_01_sampled_idx)\n",
        "\n",
        "# 새로운 라벨 분포 확인\n",
        "new_unique, new_counts = np.unique(new_label_data, axis=0, return_counts=True)\n",
        "new_label_counts = {str(label): count for label, count in zip(new_unique, new_counts)}\n",
        "\n",
        "# 출력\n",
        "print(\"\\nNew label distribution:\")\n",
        "for label, count in new_label_counts.items():\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "# 새로운 라벨 분포를 시각화\n",
        "new_labels = [str(label) for label in new_unique]\n",
        "new_counts = new_counts\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(new_labels, new_counts, color='skyblue')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.title('New Label Distribution')\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dgkRuiIyHI7c"
      },
      "id": "dgkRuiIyHI7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_mel_data.shape)\n",
        "print(new_mfcc_data.shape)\n",
        "\n",
        "print(new_label_data.shape)\n",
        "print(new_label_data[0])\n",
        "\n",
        "#check for NAN values\n",
        "print(np.isnan(new_mel_data).any())\n",
        "print(np.isnan(new_mfcc_data).any())\n",
        "print(np.isnan(new_label_data).any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZCRfvipKAzW",
        "outputId": "e2c63a0a-06b7-46c8-8839-4447c0f1f347"
      },
      "id": "sZCRfvipKAzW",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40767, 128, 128)\n",
            "(40767, 128, 128)\n",
            "(40767, 2)\n",
            "[1. 0.]\n",
            "False\n",
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SimplifiedCNNMultiLabel(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=2):\n",
        "        super(SimplifiedCNNMultiLabel, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            self._conv_block(in_channels, 32),\n",
        "            nn.MaxPool2d(2),\n",
        "            self._conv_block(32, 64),\n",
        "            nn.MaxPool2d(2),\n",
        "            self._conv_block(64, 128),\n",
        "            nn.MaxPool2d(2),\n",
        "            self._conv_block(128, 256),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def _conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "LeTOyLZ6J5Lx"
      },
      "id": "LeTOyLZ6J5Lx",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ImprovedCNNMultiLabel(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=2):\n",
        "        super(ImprovedCNNMultiLabel, self).__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            self._conv_block(in_channels, 32),\n",
        "            nn.MaxPool2d(2),\n",
        "            self._conv_block(32, 64),\n",
        "            nn.MaxPool2d(2),\n",
        "            self._conv_block(64, 128),\n",
        "            nn.MaxPool2d(2),\n",
        "            self._conv_block(128, 256),\n",
        "            nn.MaxPool2d(2),\n",
        "            self._conv_block(256, 512),\n",
        "            nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def _conv_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, groups=out_channels),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return torch.sigmoid(x)"
      ],
      "metadata": {
        "id": "0eFJvJSDjmeF"
      },
      "id": "0eFJvJSDjmeF",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "def clip_predictions(predictions, epsilon=1e-7):\n",
        "    return torch.clamp(predictions, epsilon, 1 - epsilon)\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=CONFIG.N_EPOCHS):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    best_model = None\n",
        "\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=2, verbose=True)\n",
        "    best_auc = 0.0\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_aucs = []\n",
        "    val_aucs = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_train_loss = 0.0\n",
        "        epoch_train_preds = []\n",
        "        epoch_train_labels = []\n",
        "\n",
        "        for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs}'):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            outputs = clip_predictions(outputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG.CLIP_VALUE)\n",
        "\n",
        "            optimizer.step()\n",
        "            epoch_train_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            preds = torch.sigmoid(outputs).cpu().detach().numpy()\n",
        "            epoch_train_preds.append(preds)\n",
        "            epoch_train_labels.append(labels.cpu().numpy())\n",
        "\n",
        "        epoch_train_loss /= len(train_loader.dataset)\n",
        "        train_losses.append(epoch_train_loss)\n",
        "\n",
        "        epoch_train_preds = np.concatenate(epoch_train_preds)\n",
        "        epoch_train_labels = np.concatenate(epoch_train_labels)\n",
        "\n",
        "        train_auc = roc_auc_score(epoch_train_labels, epoch_train_preds, average='weighted')\n",
        "\n",
        "        train_aucs.append(train_auc)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "        epoch_val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                val_preds.append(torch.sigmoid(outputs).cpu().detach().numpy())\n",
        "                val_labels.append(labels.cpu().numpy())\n",
        "                loss = criterion(outputs, labels)\n",
        "                epoch_val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        val_preds = np.concatenate(val_preds)\n",
        "        val_labels = np.concatenate(val_labels)\n",
        "        epoch_val_loss /= len(val_loader.dataset)\n",
        "        val_losses.append(epoch_val_loss)\n",
        "\n",
        "        val_auc = roc_auc_score(val_labels, val_preds, average='weighted')\n",
        "\n",
        "        val_aucs.append(val_auc)\n",
        "\n",
        "        # Print training and validation metrics\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, \"\n",
        "              f\"Train Loss: {epoch_train_loss:.4f}, Train AUC: {train_auc:.4f}, \"\n",
        "              f\"Val Loss: {epoch_val_loss:.4f}, Val AUC: {val_auc:.4f}\")\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(val_auc)\n",
        "\n",
        "        # Update best model if current AUC is better\n",
        "        if val_auc > best_auc:\n",
        "            best_auc = val_auc\n",
        "            best_model = model.state_dict()\n",
        "\n",
        "    # Load best model\n",
        "    model.load_state_dict(best_model)\n",
        "\n",
        "    return model, best_auc\n",
        "\n",
        "# Main loop\n",
        "auc_list = []\n",
        "pred_list_mel = []  # Store predictions for Mel model\n",
        "pred_list_mfcc = []  # Store predictions for MFCC model\n",
        "skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=CONFIG.SEED)"
      ],
      "metadata": {
        "id": "NduNrMmyKFsz"
      },
      "id": "NduNrMmyKFsz",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict on multiple segments and aggregate results\n",
        "def prediction(model, test_mfcc_data, device):\n",
        "    model.eval()\n",
        "    preds_list = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(test_mfcc_data), 2):\n",
        "            data_1 = test_mfcc_data[i]\n",
        "            data_2 = test_mfcc_data[i + 1]\n",
        "\n",
        "            inputs_1 = torch.Tensor(data_1).unsqueeze(0).unsqueeze(0).to(device)  # Assuming segment shape is (1, 1, segment_length)\n",
        "            inputs_2 = torch.Tensor(data_2).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "            preds_1 = model(inputs_1)\n",
        "            preds_2 = model(inputs_2)\n",
        "\n",
        "            # Take the average of predictions\n",
        "            preds_avg = (preds_1 + preds_2) / 2.0\n",
        "            preds_list.append(preds_avg.cpu().detach().numpy())\n",
        "\n",
        "    return preds_list\n"
      ],
      "metadata": {
        "id": "ABnBMeXsKPHk"
      },
      "id": "ABnBMeXsKPHk",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over folds\n",
        "for fold, (train_index, val_index) in enumerate(skf.split(mel_data, np.argmax(label_data, axis=1))):\n",
        "    print(f'\\n********** {fold+1} fold **********')\n",
        "\n",
        "    # Mel spectrogram model\n",
        "    #model_mel = SimplifiedCNNMultiLabel()\n",
        "    model_mel = ImprovedCNNMultiLabel()\n",
        "\n",
        "    #x_train_mel, x_val_mel = new_mel_data[train_index], new_mel_data[val_index]\n",
        "    #y_train_mel, y_val_mel = new_label_data[train_index], new_label_data[val_index]\n",
        "\n",
        "    x_train_mel, x_val_mel = mel_data[train_index], mel_data[val_index]\n",
        "    y_train_mel, y_val_mel = label_data[train_index], label_data[val_index]\n",
        "\n",
        "    train_dataset_mel = TensorDataset(torch.Tensor(x_train_mel).unsqueeze(1), torch.Tensor(y_train_mel))\n",
        "    val_dataset_mel = TensorDataset(torch.Tensor(x_val_mel).unsqueeze(1), torch.Tensor(y_val_mel))\n",
        "\n",
        "    train_loader_mel = DataLoader(train_dataset_mel, batch_size=CONFIG.BATCH_SIZE, shuffle=True)\n",
        "    val_loader_mel = DataLoader(val_dataset_mel, batch_size=CONFIG.BATCH_SIZE)\n",
        "\n",
        "    #criterion_mel = nn.BCELoss(weight=class_weights)\n",
        "    criterion_mel = nn.BCELoss()\n",
        "    optimizer_mel = optim.Adam(model_mel.parameters(), lr=CONFIG.LR)\n",
        "\n",
        "    # Mel spectrogram model\n",
        "\n",
        "    model_mel, best_auc_mel = train_model(model_mel, train_loader_mel, val_loader_mel, criterion_mel, optimizer_mel)\n",
        "\n",
        "    # Validation on full 5-second validation data for Mel model\n",
        "    model_mel.eval()\n",
        "\n",
        "    val_preds_mel = []\n",
        "    val_labels_mel = []\n",
        "\n",
        "    batch_size = CONFIG.BATCH_SIZE\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(x_val_mel), batch_size):  # Batch processing\n",
        "            inputs = torch.Tensor(x_val_mel[i:i+ batch_size]).to(device).unsqueeze(1)\n",
        "            outputs = model_mel(inputs)\n",
        "            val_preds_mel.extend(outputs.cpu().numpy())\n",
        "            val_labels_mel.extend(y_val_mel[i:i+ batch_size])\n",
        "\n",
        "    val_preds_mel = np.array(val_preds_mel)\n",
        "    val_labels_mel = np.array(val_labels_mel)\n",
        "    auc_mel = roc_auc_score(val_labels_mel, val_preds_mel, average='weighted')\n",
        "\n",
        "    print(f'mels_model_auc : {auc_mel:.4f}')\n",
        "\n",
        "    # Store predictions on test data for Mel model\n",
        "    preds_test_mel = prediction(model_mel, test_mel_data, device)\n",
        "    pred_list_mel.append(preds_test_mel)\n",
        "\n",
        "    # MFCC model\n",
        "    #model_mfcc = MultiLabelResNet()\n",
        "    #model_mfcc = SimplifiedCNNMultiLabel()\n",
        "    model_mfcc = ImprovedCNNMultiLabel()\n",
        "\n",
        "    #x_train_mfcc, x_val_mfcc = new_mfcc_data[train_index], new_mfcc_data[val_index]\n",
        "    #y_train_mfcc, y_val_mfcc = new_label_data[train_index], new_label_data[val_index]\n",
        "\n",
        "    x_train_mfcc, x_val_mfcc = mfcc_data[train_index], mfcc_data[val_index]\n",
        "    y_train_mfcc, y_val_mfcc = label_data[train_index], label_data[val_index]\n",
        "\n",
        "    train_dataset_mfcc = TensorDataset(torch.Tensor(x_train_mfcc).unsqueeze(1), torch.Tensor(y_train_mfcc))\n",
        "    val_dataset_mfcc = TensorDataset(torch.Tensor(x_val_mfcc).unsqueeze(1), torch.Tensor(y_val_mfcc))\n",
        "    train_loader_mfcc = DataLoader(train_dataset_mfcc, batch_size=CONFIG.BATCH_SIZE, shuffle=True)\n",
        "    val_loader_mfcc = DataLoader(val_dataset_mfcc, batch_size=CONFIG.BATCH_SIZE)\n",
        "\n",
        "    optimizer_mfcc = optim.Adam(model_mfcc.parameters(), lr=CONFIG.LR)\n",
        "\n",
        "    #criterion_mfcc = nn.BCELoss(weight=class_weights)\n",
        "    criterion_mfcc = nn.BCELoss()\n",
        "\n",
        "    model_mfcc, best_auc_mfcc = train_model(model_mfcc, train_loader_mfcc, val_loader_mfcc, criterion_mel, optimizer_mfcc)\n",
        "\n",
        "    # Validation on full 5-second validation data for MFCC model\n",
        "    model_mfcc.eval()\n",
        "    val_preds_mfcc = []\n",
        "    val_labels_mfcc = []\n",
        "\n",
        "    batch_size = CONFIG.BATCH_SIZE\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(x_val_mfcc), batch_size):  # Batch processing\n",
        "            inputs = torch.Tensor(x_val_mfcc[i:i+batch_size]).to(device).unsqueeze(1)\n",
        "            outputs = model_mfcc(inputs)\n",
        "            val_preds_mfcc.extend(outputs.cpu().numpy())\n",
        "            val_labels_mfcc.extend(y_val_mel[i:i+batch_size])\n",
        "\n",
        "    val_preds_mfcc = np.array(val_preds_mfcc)\n",
        "    val_labels_mfcc = np.array(val_labels_mfcc)\n",
        "    auc_mfcc = roc_auc_score(val_labels_mfcc, val_preds_mfcc, average='weighted')\n",
        "\n",
        "    print(f'mfcc_model_auc : {auc_mfcc:.4f}')\n",
        "\n",
        "    # Store predictions on test data for MFCC model\n",
        "    preds_test_mfcc = prediction(model_mfcc, test_mfcc_data, device)\n",
        "    pred_list_mfcc.append(preds_test_mfcc)\n",
        "\n",
        "    # Print fold ensemble metrics if needed\n",
        "    print(f'Ensemble metrics for fold {fold+1}')\n",
        "\n",
        "# Calculate mean predictions from all folds\n",
        "pred_mean_mel = np.mean(pred_list_mel, axis=0)\n",
        "pred_mean_mfcc = np.mean(pred_list_mfcc, axis=0)\n",
        "\n",
        "# Perform final ensemble by averaging predictions\n",
        "final_pred_mean = (pred_mean_mel + pred_mean_mfcc) / 2.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q4oRmlUaKKqT",
        "outputId": "9ce6f367-0b59-43d8-9eb9-0263ee743ba5"
      },
      "id": "q4oRmlUaKKqT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "********** 1 fold **********\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 874/874 [01:07<00:00, 12.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.2554, Train AUC: 0.9606, Val Loss: 0.6918, Val AUC: 0.9536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 874/874 [01:08<00:00, 12.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Train Loss: 0.1173, Train AUC: 0.9909, Val Loss: 0.1398, Val AUC: 0.9928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Train Loss: 0.0844, Train AUC: 0.9948, Val Loss: 0.0678, Val AUC: 0.9974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Train Loss: 0.0659, Train AUC: 0.9966, Val Loss: 0.0564, Val AUC: 0.9981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 874/874 [01:08<00:00, 12.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Train Loss: 0.0535, Train AUC: 0.9976, Val Loss: 0.0449, Val AUC: 0.9986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Train Loss: 0.0473, Train AUC: 0.9982, Val Loss: 0.0625, Val AUC: 0.9981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Train Loss: 0.0394, Train AUC: 0.9986, Val Loss: 0.0770, Val AUC: 0.9987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 874/874 [01:08<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Train Loss: 0.0345, Train AUC: 0.9990, Val Loss: 0.0469, Val AUC: 0.9985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Train Loss: 0.0144, Train AUC: 0.9997, Val Loss: 0.0255, Val AUC: 0.9995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Train Loss: 0.0090, Train AUC: 0.9999, Val Loss: 0.0306, Val AUC: 0.9995\n",
            "mels_model_auc : 0.9995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.4319, Train AUC: 0.8824, Val Loss: 0.4441, Val AUC: 0.9008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Train Loss: 0.2096, Train AUC: 0.9723, Val Loss: 0.1514, Val AUC: 0.9889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Train Loss: 0.1447, Train AUC: 0.9861, Val Loss: 0.1471, Val AUC: 0.9869\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 874/874 [01:08<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Train Loss: 0.1206, Train AUC: 0.9901, Val Loss: 0.3769, Val AUC: 0.9533\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 874/874 [01:08<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Train Loss: 0.1007, Train AUC: 0.9930, Val Loss: 0.0882, Val AUC: 0.9963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Train Loss: 0.0864, Train AUC: 0.9947, Val Loss: 0.0739, Val AUC: 0.9970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Train Loss: 0.0742, Train AUC: 0.9960, Val Loss: 0.0747, Val AUC: 0.9966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 874/874 [01:08<00:00, 12.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Train Loss: 0.0648, Train AUC: 0.9967, Val Loss: 0.4523, Val AUC: 0.9621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Train Loss: 0.0512, Train AUC: 0.9978, Val Loss: 0.1865, Val AUC: 0.9890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 874/874 [01:08<00:00, 12.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Train Loss: 0.0230, Train AUC: 0.9995, Val Loss: 0.0541, Val AUC: 0.9985\n",
            "mfcc_model_auc : 0.9985\n",
            "Ensemble metrics for fold 1\n",
            "\n",
            "********** 2 fold **********\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 874/874 [01:08<00:00, 12.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.2527, Train AUC: 0.9612, Val Loss: 0.3363, Val AUC: 0.9805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Train Loss: 0.1168, Train AUC: 0.9908, Val Loss: 0.1303, Val AUC: 0.9940\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Train Loss: 0.0858, Train AUC: 0.9945, Val Loss: 0.0559, Val AUC: 0.9977\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Train Loss: 0.0691, Train AUC: 0.9964, Val Loss: 0.1047, Val AUC: 0.9970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 874/874 [01:08<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Train Loss: 0.0563, Train AUC: 0.9974, Val Loss: 0.0464, Val AUC: 0.9987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Train Loss: 0.0490, Train AUC: 0.9980, Val Loss: 0.0564, Val AUC: 0.9981\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Train Loss: 0.0410, Train AUC: 0.9985, Val Loss: 0.0487, Val AUC: 0.9984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Train Loss: 0.0365, Train AUC: 0.9988, Val Loss: 0.0493, Val AUC: 0.9985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Train Loss: 0.0166, Train AUC: 0.9997, Val Loss: 0.0285, Val AUC: 0.9992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Train Loss: 0.0099, Train AUC: 0.9998, Val Loss: 0.0290, Val AUC: 0.9993\n",
            "mels_model_auc : 0.9993\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.4341, Train AUC: 0.8784, Val Loss: 0.3284, Val AUC: 0.9398\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 874/874 [01:08<00:00, 12.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Train Loss: 0.2088, Train AUC: 0.9727, Val Loss: 0.1366, Val AUC: 0.9887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 874/874 [01:08<00:00, 12.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Train Loss: 0.1477, Train AUC: 0.9859, Val Loss: 0.1769, Val AUC: 0.9885\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Train Loss: 0.1206, Train AUC: 0.9905, Val Loss: 0.0986, Val AUC: 0.9937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Train Loss: 0.1011, Train AUC: 0.9929, Val Loss: 0.0736, Val AUC: 0.9963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Train Loss: 0.0860, Train AUC: 0.9949, Val Loss: 0.1016, Val AUC: 0.9952\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Train Loss: 0.0764, Train AUC: 0.9959, Val Loss: 0.0714, Val AUC: 0.9966\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Train Loss: 0.0631, Train AUC: 0.9971, Val Loss: 0.0768, Val AUC: 0.9959\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 874/874 [01:08<00:00, 12.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Train Loss: 0.0567, Train AUC: 0.9975, Val Loss: 0.0846, Val AUC: 0.9960\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 874/874 [01:08<00:00, 12.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Train Loss: 0.0520, Train AUC: 0.9979, Val Loss: 0.1230, Val AUC: 0.9959\n",
            "mfcc_model_auc : 0.9959\n",
            "Ensemble metrics for fold 2\n",
            "\n",
            "********** 3 fold **********\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 874/874 [01:08<00:00, 12.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.2519, Train AUC: 0.9616, Val Loss: 0.1579, Val AUC: 0.9915\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Train Loss: 0.1175, Train AUC: 0.9907, Val Loss: 0.0771, Val AUC: 0.9964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Train Loss: 0.0894, Train AUC: 0.9943, Val Loss: 0.0829, Val AUC: 0.9970\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 874/874 [01:08<00:00, 12.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Train Loss: 0.0677, Train AUC: 0.9964, Val Loss: 0.0542, Val AUC: 0.9978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 874/874 [01:08<00:00, 12.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Train Loss: 0.0591, Train AUC: 0.9974, Val Loss: 0.0516, Val AUC: 0.9984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Train Loss: 0.0495, Train AUC: 0.9980, Val Loss: 0.0568, Val AUC: 0.9986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Train Loss: 0.0429, Train AUC: 0.9984, Val Loss: 0.0430, Val AUC: 0.9988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 874/874 [01:08<00:00, 12.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Train Loss: 0.0384, Train AUC: 0.9986, Val Loss: 0.0579, Val AUC: 0.9988\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Train Loss: 0.0329, Train AUC: 0.9990, Val Loss: 0.0597, Val AUC: 0.9990\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Train Loss: 0.0256, Train AUC: 0.9994, Val Loss: 0.0519, Val AUC: 0.9989\n",
            "mels_model_auc : 0.9989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.4333, Train AUC: 0.8809, Val Loss: 0.3292, Val AUC: 0.9524\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 874/874 [01:08<00:00, 12.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Train Loss: 0.2005, Train AUC: 0.9744, Val Loss: 0.1291, Val AUC: 0.9897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 874/874 [01:08<00:00, 12.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Train Loss: 0.1468, Train AUC: 0.9860, Val Loss: 0.2225, Val AUC: 0.9902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 874/874 [01:08<00:00, 12.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Train Loss: 0.1197, Train AUC: 0.9904, Val Loss: 0.0931, Val AUC: 0.9944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10, Train Loss: 0.0978, Train AUC: 0.9932, Val Loss: 0.1176, Val AUC: 0.9926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10, Train Loss: 0.0831, Train AUC: 0.9951, Val Loss: 0.1676, Val AUC: 0.9951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10, Train Loss: 0.0729, Train AUC: 0.9962, Val Loss: 0.2072, Val AUC: 0.9934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10, Train Loss: 0.0621, Train AUC: 0.9970, Val Loss: 0.0978, Val AUC: 0.9957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10, Train Loss: 0.0536, Train AUC: 0.9978, Val Loss: 0.0931, Val AUC: 0.9965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10, Train Loss: 0.0461, Train AUC: 0.9982, Val Loss: 0.0937, Val AUC: 0.9972\n",
            "mfcc_model_auc : 0.9972\n",
            "Ensemble metrics for fold 3\n",
            "\n",
            "********** 4 fold **********\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/10: 100%|██████████| 874/874 [01:08<00:00, 12.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Train Loss: 0.2508, Train AUC: 0.9610, Val Loss: 0.2169, Val AUC: 0.9911\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/10: 100%|██████████| 874/874 [01:08<00:00, 12.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10, Train Loss: 0.1151, Train AUC: 0.9910, Val Loss: 0.0661, Val AUC: 0.9973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/10: 100%|██████████| 874/874 [01:08<00:00, 12.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10, Train Loss: 0.0895, Train AUC: 0.9943, Val Loss: 0.1127, Val AUC: 0.9963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/10: 100%|██████████| 874/874 [01:08<00:00, 12.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10, Train Loss: 0.0710, Train AUC: 0.9963, Val Loss: 0.0679, Val AUC: 0.9972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/10:  94%|█████████▍| 822/874 [01:04<00:04, 12.79it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "torch.save(model_mel.state_dict(), '/content/drive/MyDrive/DACON/chunk/aug2_model_mel.pth')\n",
        "torch.save(model_mfcc.state_dict(), '/content/drive/MyDrive/DACON/chunk/aug2_model_mfcc.pth')"
      ],
      "metadata": {
        "id": "0VePZ5pJKSG2"
      },
      "id": "0VePZ5pJKSG2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "%cd /content/drive/MyDrive/DACON\n",
        "submit = pd.read_csv('./sample_submission.csv')\n",
        "#submit=submit[:len(y_valid)]\n",
        "submit.head(3)\n",
        "submit.shape"
      ],
      "metadata": {
        "id": "P9KchanYO9rh"
      },
      "id": "P9KchanYO9rh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pred_mean.shape\n",
        "\n",
        "# final_pred_mean의 형태를 (50000, 2)로 변환\n",
        "final_pred_mean_reshaped = final_pred_mean.reshape((50000, 2))\n",
        "\n",
        "final_pred_mean_reshaped.shape"
      ],
      "metadata": {
        "id": "agWr02fSO_Hw"
      },
      "id": "agWr02fSO_Hw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.iloc[:, 1:] = final_pred_mean_reshaped\n",
        "\n",
        "submit.head(10)"
      ],
      "metadata": {
        "id": "1LFIl-yTPALl"
      },
      "id": "1LFIl-yTPALl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# preds가 리스트인 경우 numpy 배열로 변환\n",
        "preds = np.array(final_pred_mean_reshaped)\n",
        "\n",
        "# 예측값의 통계 정보 확인\n",
        "print(\"Preds statistics:\")\n",
        "print(pd.DataFrame(preds).describe())\n",
        "\n",
        "# NaN 값 확인\n",
        "nan_mask = np.isnan(preds)\n",
        "print(\"Number of NaN values:\", np.sum(nan_mask))\n",
        "\n",
        "# NaN 값을 0으로 대체 (또는 다른 적절한 값으로 대체 가능)\n",
        "preds = np.nan_to_num(preds)\n",
        "\n",
        "# 히스토그램으로 분포 시각화\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Real 레이블의 분포\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(preds[:, 1], bins=50, alpha=0.75, color='blue', label='Real')\n",
        "plt.title('Distribution of Real Predictions')\n",
        "plt.xlabel('Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "\n",
        "# Fake 레이블의 분포\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(preds[:, 0], bins=50, alpha=0.75, color='red', label='Fake')\n",
        "plt.title('Distribution of Fake Predictions')\n",
        "plt.xlabel('Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 가짜 음성을 분류하지 못하는지 확인\n",
        "fake_preds = preds[:, 0]\n",
        "real_preds = preds[:, 1]\n",
        "\n",
        "# Fake 레이블에 대한 기본 통계 확인\n",
        "print(\"\\nFake label predictions:\")\n",
        "print(f\"Min: {fake_preds.min()}\")\n",
        "print(f\"Max: {fake_preds.max()}\")\n",
        "print(f\"Mean: {fake_preds.mean()}\")\n",
        "print(f\"Median: {np.median(fake_preds)}\")\n",
        "\n",
        "# Real 레이블에 대한 기본 통계 확인\n",
        "print(\"\\nReal label predictions:\")\n",
        "print(f\"Min: {real_preds.min()}\")\n",
        "print(f\"Max: {real_preds.max()}\")\n",
        "print(f\"Mean: {real_preds.mean()}\")\n",
        "print(f\"Median: {np.median(real_preds)}\")\n"
      ],
      "metadata": {
        "id": "G_kNX9yKPCwu"
      },
      "id": "G_kNX9yKPCwu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit.iloc[:, 1:] = preds\n",
        "submit.to_csv('0715_mels_mfcc_aug_ImprovedCNN.csv', index=False)"
      ],
      "metadata": {
        "id": "oXz41IjhPDb7"
      },
      "id": "oXz41IjhPDb7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpRjG2IUPFon",
        "outputId": "15b4b145-5fa0-4da9-fb66-772dbb085061"
      },
      "id": "mpRjG2IUPFon",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 8068726,
          "sourceId": 70203,
          "sourceType": "competition"
        },
        {
          "datasetId": 4732842,
          "sourceId": 8066583,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30674,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 1830.928153,
      "end_time": "2024-04-08T19:22:15.265404",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-04-08T18:51:44.337251",
      "version": "2.5.0"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}