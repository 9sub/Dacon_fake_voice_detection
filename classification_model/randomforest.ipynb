{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import os\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    SR = 32000\n",
    "    N_MFCC = 128\n",
    "    # Dataset\n",
    "    ROOT_FOLDER = './'\n",
    "    # Training\n",
    "    N_CLASSES = 2\n",
    "    BATCH_SIZE = 96\n",
    "    N_EPOCHS = 5\n",
    "    LR = 3e-4\n",
    "    # Others\n",
    "    SEED = 42\n",
    "\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['path'] = df['path'].str.replace('./train/', './bandstop_train/')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_label = np.load('./mfcc/aug_label_data.npy')\n",
    "aug_mfcc = np.load('./mfcc/aug_mfcc_data.npy')\n",
    "\n",
    "aug_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# CSV 파일 경로\n",
    "csv_file_path1 = './train.csv'  # 레이블이 'fake', 'real' 형식인 파일\n",
    "csv_file_path2 = './unlabeled_data.csv'  # 레이블이 이미 [0,1], [1,0] 형식인 파일\n",
    "\n",
    "# 첫 번째 CSV 파일 불러오기\n",
    "df1 = pd.read_csv(csv_file_path1)\n",
    "\n",
    "# 'fake', 'real' 레이블을 [1,0], [0,1] 형식으로 변환\n",
    "def convert_label(label):\n",
    "    return [1, 0] if label == 'fake' else [0, 1]\n",
    "\n",
    "df1['label'] = df1['label'].apply(convert_label)\n",
    "df1['path'] = df1['path'].str.replace('./train', './bandstop_train')\n",
    "# 두 번째 CSV 파일 불러오기\n",
    "df2 = pd.read_csv(csv_file_path2,nrows=477)\n",
    "def convert_to_numpy(label):\n",
    "    return ast.literal_eval(label)\n",
    "\n",
    "df2['label'] = df2['label'].apply(convert_to_numpy)\n",
    "#print(df2['label'])\n",
    "#df2['path'] = df2['path'].str.replace('./unlabeled_data', './bandstop_unlabeled_data')\n",
    "# 두 데이터프레임 결합\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# 데이터프레임 섞기 (선택사항)\n",
    "combined_df = combined_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "df = pd.read_csv('./unlabeled_data.csv',nrows=600)\n",
    "def convert_to_numpy(label):\n",
    "    return ast.literal_eval(label)\n",
    "\n",
    "df['label'] = df['label'].apply(convert_to_numpy)\n",
    "#print(df2['label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(combined_df, combined_df['label'], test_size=0.2, random_state=CONFIG.SEED)\n",
    "train.shape, val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_feature(df, train_mode=True):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        # librosa패키지를 사용하여 wav 파일 load\n",
    "        y, sr = librosa.load(row['path'], sr=CONFIG.SR)\n",
    "        # librosa패키지를 사용하여 mfcc 추출\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
    "        mfcc = np.mean(mfcc.T, axis=0)\n",
    "        features.append(mfcc)\n",
    "\n",
    "        if train_mode:\n",
    "            label = row['label']\n",
    "            \n",
    "            label_vector = np.array((label), dtype=float)\n",
    "            labels.append(label_vector)\n",
    "            #label_vector = [1,0] if label == 'fake' else [0,1]\n",
    "            #label_vector2 = np.array((label_vector), dtype=float)\n",
    "\n",
    "\n",
    "\n",
    "            #label_vector[0 if label == 'fake' else 1] = 1\n",
    "            #labels.append(label_vector2)\n",
    "\n",
    "    if train_mode:\n",
    "        return features, labels\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mfcc, train_labels = get_mfcc_feature(train, True)\n",
    "val_mfcc, val_labels = get_mfcc_feature(val, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_mfcc = np.load('./mfcc/aug_mfcc_mean_data.npy')\n",
    "aug_label = np.load('./mfcc/aug_label_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_X_train, aug_X_val,aug_y_train,aug_y_val = train_test_split(aug_mfcc,aug_label, test_size=0.2, random_state=CONFIG.SEED)\n",
    "aug_X_train.shape, aug_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_mfcc = np.load('./mfcc/bandstop_with_unlabel_train_mfcc.npy')\n",
    "train_labels=np.load('./mfcc/bandstop_with_unlabel_train_labels.npy')\n",
    "val_mfcc = np.load('./mfcc/bandstop_with_unlabel_val_mfcc.npy')\n",
    "val_labels = np.load('./mfcc/bandstop_with_unlabel_val_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=CONFIG.SEED)\n",
    "kf = KFold(n_splits=5, random_state=CONFIG.SEED, shuffle=True)\n",
    "\n",
    "print(model)\n",
    "print(kf.get_n_splits(aug_X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(train_mfcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'n_estimators' : [10, 50,100],\n",
    "           'max_depth' : [6, 8, 10, 12],\n",
    "           'min_samples_leaf' : [8, 12, 18],\n",
    "           'min_samples_split' : [8, 16, 20]\n",
    "            }\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state = CONFIG.SEED)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 5, verbose=2, n_jobs = -1)\n",
    "grid_cv.fit(aug_X_train, aug_y_train )\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'n_estimators' : [100,150,200],\n",
    "           'max_depth' : [12,15,18,21],\n",
    "           'min_samples_leaf' : [6,7,8],\n",
    "           'min_samples_split' : [6,7,8]\n",
    "            }\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state = CONFIG.SEED)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 5, verbose=2, n_jobs = -1)\n",
    "grid_cv.fit(aug_X_train, aug_y_train )\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'n_estimators' : [140,150,160],\n",
    "           'max_depth' : [21,23,25,27],\n",
    "           'min_samples_leaf' : [4,5,6],\n",
    "           'min_samples_split' : [4,5,6]\n",
    "            }\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state = CONFIG.SEED)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 5, verbose=2, n_jobs = -1)\n",
    "grid_cv.fit(aug_X_train, aug_y_train )\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'n_estimators' : [135,140,145],\n",
    "           'max_depth' : [27,28,29],\n",
    "           'min_samples_leaf' : [2,3,4],\n",
    "           'min_samples_split' : [2,3,4]\n",
    "            }\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state = CONFIG.SEED)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 5, verbose=2, n_jobs = -1)\n",
    "grid_cv.fit(aug_X_train, aug_y_train )\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'n_estimators' : [195,200, 205],\n",
    "           'max_depth' : [26,28,30],\n",
    "           'min_samples_leaf' : [3,4,5],\n",
    "           'min_samples_split' : [3,4,5]\n",
    "            }\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state = CONFIG.SEED)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 5, verbose=2, n_jobs = -1)\n",
    "grid_cv.fit(train_mfcc, train_labels )\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = { 'n_estimators' : [200, 205,210],\n",
    "           'max_depth' : [30,32,34],\n",
    "           'min_samples_leaf' : [1,2,3],\n",
    "           'min_samples_split' : [1,2,3]\n",
    "            }\n",
    "\n",
    "# RandomForestClassifier 객체 생성 후 GridSearchCV 수행\n",
    "rf_clf = RandomForestClassifier(random_state = CONFIG.SEED)\n",
    "grid_cv = GridSearchCV(rf_clf, param_grid = params, cv = 5, verbose=2, n_jobs = -1)\n",
    "grid_cv.fit(train_mfcc, train_labels )\n",
    "\n",
    "print('최적 하이퍼 파라미터: ', grid_cv.best_params_)\n",
    "print('최고 예측 정확도: {:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = rf_clf1.predict(val_mfcc)\n",
    "test = pd.read_csv('./test.csv')\n",
    "test_mfcc = get_mfcc_feature(test, False)\n",
    "print(test_mfcc)\n",
    "'''\n",
    "best_rf_clf = grid_cv.best_estimator_\n",
    "\n",
    "# 각 클래스의 확률을 예측\n",
    "probs = best_rf_clf.predict_proba(val_mfcc)\n",
    "\n",
    "print((probs))\n",
    "#print('예측 정확도: {:.4f}'.format(accuracy_score(val_labels,probs)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./mfcc/test_mfcc_[0,1]_form.npy', test_mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mfcc = np.load('./mfcc/test_mfcc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_clf = grid_cv.best_estimator_\n",
    "print(len(test_mfcc))\n",
    "probs = best_rf_clf.predict_proba(test_mfcc)\n",
    "\n",
    "print(len(probs[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "print(submit.info)\n",
    "submit.iloc[:, 1:] = probs\n",
    "submit = submit.set_index('id')\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(submit.info)\n",
    "submit.to_csv('./aug_mfcc_randomforest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
